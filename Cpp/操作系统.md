# 操作系统

## 计算机的层次结构

![操作系统的层次结构](D:\C++学习笔记\OSpicture\操作系统的层次结构.PNG)

如上图所示,计算机的层次结构有四层,操作系统位于软件与硬件之间的中间层,它负责管理协调硬件,软件等计算机资源的工作.它还会为用户提供接口,它是最接近硬件的软件.

**操作系统定义**

操作系统(Operating System)是指控制和管理整个计算机系统的硬件和软件资源,并合理组织调度计算机的工作和资源的分配,以提供给用户和其他软件方便的接口和环境,它是计算机系统中最基本的系统软件.

**操作系统的功能和目标**

在操作系统的层次结构中,我们可以看见它与用户,软件,硬件层都有联系.因此它是可以为这三者都提供服务的.

* 操作系统可以作为系统资源的管理者

  * 处理机(CPU)管理
  * 存储器管理
  * 文件管理
  * 设备管理

  * 目标 : 安全高效的进行资源调度

* 操作系统可以作为用户和计算机硬件之间的接口

  * 命令接口(允许用户直接使用)

    * 联机命令接口(交互式命令接口)

      在windows系统下,就是我们那个cmd命令界面

    * 脱机命令接口(批处理命令接口)

      在windows系统下那些.bat后缀的文件就是批处理文件,它里面就是各种单行的交互式命令

  * 程序接口(允许用户间接调用)

    程序接口由一组系统调用组成.系统调用也称为广义指令

    比如在windows系统下,我们通过调用静态库,也就是系统提供的user32.dll,可以在C/C++里直接调用,这个过程称为系统调用,然后可以实现创建窗口等功能.这些接口只能通过用户程序进行间接调用.

  * GUI图形用户界面

    GUI(Graphical User Interface)是一种图形化的界面,用户不需要通过指令来进行操作了.在windows中就比如拖拽文件的这种操作就是一种GUI操作,以及我们的各种窗口,都是GUI.

  * 目标 : 方便用户的使用

* 操作系统可以作为硬件的扩展

  没有任何软件支持的计算机称为裸机,而覆盖了软件的裸机就是扩充机器,也成为虚拟机.操作系统可以扩展硬件的功能,此外,它还可以屏蔽底层的组织规律,不需要用户关心底层的组织就可以使用硬件的各种功能.这个思想是不是很像我们编程中的OOP的特性呢?它就像我们程序中的API一样,我们直接用,而不用关心实现一样.

## 操作系统的特性

操作系统的特性有四个:

并发与共享是操作系统的基本特性,二者互为存在条件.

### 并发

并发指的是两个或多个事件在同一时间间隔内发生.这些事件宏观上是同时发生的,但是微观上是交替发生的.

这里提一下容易与并发混淆的概念 : 并行 ,并行是指两个或多个事件同时发生.

对于计算机来说,操作系统的并发性是指计算机中同时存在着多个运行中的程序.而一个CPU核心同一时间只能处理一个任务,所以呢,操作系统会在这个核心上协调多个任务的交替运行,让它们看起来是同时运行的(并行)一样.

操作系统是伴随着"多道程序技术"出现的,因此操作系统和程序并发是一起诞生的.

### 共享

共享即资源共享,是指系统中的资源可供内存中多个并发执行的进程共同使用.

系统中的资源共享方式分为:

* 互斥共享

  一个时间段内只允许一个进程访问的资源(像不像Java的上锁对象?)

* 同时共享

  在一个时间段内可以由多个进程同时对它进行访问(当单线程的时候,微观上实际上还是分时共享的

我们前面为啥说并发和共享是互为存在关系呢?

对于并发性来说,如果没有共享性,那么多个程序不可以同时访问资源,那么就做不到并发;而对于共享性来说,如果没有并发的程序,也就是只存在一个运行的程序,那么共享就失去了存在的意义.

### 虚拟

虚拟是指把物理上的实体变为若干个逻辑上的对应物.物理上的实体是实际存在的,而逻辑上的对应物是用户感受到的.

虚拟技术

* 空分复用技术(如虚拟存储技术)
* 时分复用技术(如虚拟处理器技术)
* 对于虚拟性来讲,它存在的前提是并发性,没有并发就没有虚拟性存在的意义.

举个例子,很多程序的要求下,我们在打开很多应用程序的时候看起来需要的内存容量已经超过我们计算机中的内存容量了,但是应用还是可以正常运行,这就是因为操作系统使用了虚拟存储技术(空分复用技术),实际上只有那么点的内存,在用户看来似乎不止这么点.还有这么多程序为啥能在单核计算机系统上运行呢?这个也是操作系统使用的虚拟处理器技术(时分复用技术)来实现的(就是时间片调度的方式),让只有一个CPU的计算机使得用户看起来有好几个一样.

### 异步

异步是指,在多道程序环境下,允许多个程序并发执行,但由于资源有限,进程的执行不是一贯到底的,而是走走停停,以不可预知的速度向前推进,这就是进程的异步性.

异步的原因是因为系统的资源有限,应用程序的执行期间对于资源的掌控并不可能是全部掌握在某个应用程序中的,所以每个进程的执行并不是一贯到底的,而是会走走停停.异步的原因也是因为并发的存在,没有并发的话整个系统就是串行的了,每个应用程序都是一次走到底.所以只有系统有并发性才会导致异步性.

## 操作系统的发展和分类

操作系统的发展有以下阶段

* 手工操作阶段

  此时还没有操作系统,当时的程序都是用纸带上用孔来表示程序(机器码).在这个阶段有以下特点:

  * 处理速度快
  * 输入输出操作及其慢
  * 程序编写困难
  * 同时只能由一个用户使用一个计算机
  * 资源利用率非常低

* 批处理阶段

  * 单道批处理阶段

    此时引入了脱机输入/输出技术(磁带),并用监督程序负责控制作业的输入输出,这个监督程序就是操作系统的雏形.

    此阶段的特点:

    * 缓解了手工阶段的一部分矛盾
    * 资源利用率有所提高
    * 内存中只能由一道程序运行,计算机还是由大量时间等待IO,资源利用率仍然很低
    * ![单道批处理技术时间](D:\C++学习笔记\OSpicture\单道批处理技术时间.PNG)

  * 多道批处理阶段(操作系统的出现)

    此时计算机能够从磁带读入多道程序,这些程序可以并发执行,并且此阶段操作系统正式出现,并引入中断技术,实现了操作系统对程序的管理.这个阶段的特点:

    * 程序能够并发执行了
    * 计算机资源能够共享
    * 资源利用率大幅提升,系统吞吐量增大.
    * 没有人机交互功能,用户相应时间长,用户不能控制自己的任务执行
    * ![多道批处理技术](D:\C++学习笔记\OSpicture\多道批处理技术.PNG)

* 分时操作系统

  计算机以时间片为单位轮流为各个用户/作业服务,各个用户可以通过终端与计算机进行交互.类似于我们单线程处理线程的过程,就是以一个时间片为基准,一个时间片内为一个任务服务,

  此时的特点:

  * 任务可被实时响应,解决了用户交互问题
  * 因为是时间片机制来为任务提供服务.所以它对于一些对于实时性要求极高的任务来说是不适用的

* 实时操作系统

  实时操作系统的特点就是实时性强,实时系统又分为硬实时系统和软实时系统,区别就是是否严格在规定时间内完成任务处理.这种系统拥有很强大的及时性与可靠性

* 网络操作系统

  它的目的是为了实现网络种各种资源的共享以及计算机之间的通信,例如WindowsNT系统就是一个典型的网络操作系统,它是用于网站服务器的

* 分布式操作系统

  它的主要特点是分布性和并行性.该系统种的各台计算机地位相同,任务可用分布在这些计算机上,由它们并行协同的完成这个任务.

* 个人计算机操作系统

  它的主要目的是方便个人用户的使用,如windows 10系统和MacOS

## 操作系统的运行机制和体系结构

### 运行机制

指令 : 计算机CPU能够识别运行的命令,我们的高级程序语言经过编译后就会得到多条计算机指令.

两种指令-两种处理器状态-两种程序

* 两种指令 
  * 特权指令 : 可能会导致危险的指令,比如内存清零指令
  * 非特权指令 : 普通的指令,也就是一般的指令
* 两种处理器状态
  * 用户态(目态) : 此时只能执行非特权指令
  * 核心态(管态)
  * CPU状态由状态字寄存器(PSW)中的某一个标志位来标识的
* 两种程序
  * 内核程序 : 操作系统的内核程序是系统的管理者,这种程序可以执行任意程序.它运行在和心态,一般就是计算机内核的程序.
  * 应用程序 : 运行在用户态的程序,我们一般写的程序就是这个.

### 操作系统内核

在操作系统的层次结构中,其实操作系统还分为内核与非内核功能.

内核功能中还能分为:

* 时钟管理 : 实现计时功能
* 中断处理 
* 原语(设备驱动,CPU切换等) : 它是一种特殊的程序,是最接近硬件的部分,这种程序的运行具有原子性,一般这种程序它的调用是很频繁的.
* 进程管理,存储器管理,设备管理等等.....(系统资源管理功能)

在不同的操作系统中,内核的功能是不一样的,不过核心的内容都差不多.



### 操作系统的体系结构

实际上内核还可以分为大内核和微内核.大内核就是把各种主要功能都作为系统内核,运行在核心态.但是它的代码量比较大,比较难维护.因为全程都是核心态,所以它的性能是比较高的.而微内核只包含很基本的功能,它的内核功能很少,所以很容易维护.但是因为功能少,所以用户新增的功能是运行在用户态的,所以使用微内核的操作系统处理任务时会导致核心态与用户态的频繁切换,效率会比较低.

## 中断和异常

**中断机制**

早期计算机处理任务是串行的,后面因为操作系统的出现,并引入了中断机制,实现了并发.

所以说发生中断就意味着需要操作系统的介入,并开展管理工作.以一个三任务程序为例子:

三个用户进程启动,计算机开始处理,处理进程1的完成的时候,进程1会发出系统调用(内中断信号),请求任务完成输出,此时内中断信号会被操作系统捕获,并进行处理,它会把CPU状态切换为核心态,进行输出操作,当输出设备完成后,IO设备也会发送一个中断信号,告知CPU本次操作结束,完成处理后CPU状态回到用户态,继续处理下一个进程,也就是进程2.因为这种输出(比如请求打印机打印)是属于特权指令的,用户必须要经过操作系统才可以调用.

由上面的例子我们可以知道 : 

1. 当中断发生时,CPU立刻进入核心态,并且用户态到核心态之间只能通过中断进行.
2. 当中断发生后,当前运行的进程暂停,并由操作系统内核对中断进行处理
3. 对于不同的中断信号,会进行不同的处理.

因为中断机制的存在,计算机才能实现多道程序的并发.

**中断的分类**

* 内中断(也称作异常,陷入,例外)

  * 自愿中断

    指令中断 : 也就是系统调用(程序使用的陷入指令)

  * 强迫中断

    因为硬件故障或者软件中断引起

    硬件中断比如缺页异常,这种情况可能会被故障处理程序修复.

    软件中断比如程序中的整数除0异常

* 外中断

  外中断一般也直接称作中断.它的引起一般是因为外设请求(比如IO操作完成后外设发出的中断信号)或者人工干预(用户强制结束一个进程).

内外中断的区别是信号来源,内中断的信号来源是CPU内部,外中断是CPU外部.而且内中断是与当前执行指令有关的.

**外中断的处理过程**

* CPU在执行指令的过程中,每执行一条指令,CPU都会检查当前是否有中断信号
* 如果发现当前存在外部中断信号(比如键盘输入了一个字符),就需要保护当前被中断进程的CPU环境(如程序状态字PSW,程序计数器,各种通用寄存器状态等).

* 根据中断信号类型转入相应的中断处理程序进行处理,中断处理程序是一个内核中的一个程序.
* 处理完成后,恢复原进程的CPU环境并退出中断,继续执行原进程.



## 系统调用

**系统调用的概念与作用**

系统调用是用户和计算机硬件之间的接口.操作系统面向用户提供的是命令接口,比如windows那个cmd界面.而操作系统面对应用程序(也就是我们的软件)提供的是程序接口,也就是系统调用.它是面向应用程序开发人员的接口.

系统的共享资源由操作系统统一管理,如果由各个进程直接操作,会导致不可预知的后果,所以进程需要通过操作系统来对共享资源进行操作.这样做是为了保证系统的稳定性和安全性,防止用户程序进行非法操作.

**系统调用的分类**

* 设备管理
* 文件管理
* 进程管理
* 进程管理
* 内存管理

系统调用的相关处理必须是在核心态下完成的.它的操作全是特权操作.

**系统调用与库函数**

虽然说系统调用是防止用户(也就是普通应用程序)进行非法操作的,但是它其实是可以直接使用汇编语言进行调用的.不过呢,目前我们在高级语言中的库函数调用,比如C语言提供的标准库,我们其实也是在通过库函数去调用系统调用的,比如C库里面的文件操作API.

**系统调用的背后过程**

系统调用中其实就是使用了中断指令,切换到核心态并进行相关处理.所以可以说系统调用就是一种中断操作.操作就对应着中断表.自己康去.



## 进程

**进程出现的原因**

程序 : 就是指指令序列.

计算机在运行程序的时候,会先把它读到内存里去.此时内存里面会包含程序段和数据段.当程序有多道并发到时候,外设可能也是被分配给不同的程序的,所以此时为了完成个程序并发的需求,引入了进程,进程实体的概念.此时系统会为每个运行的程序配置一个数据结构,称为进程控制块(PCB,不是电路板嗷),用来描述进程的各种信息,包括程序段数据段的位置,分配的外设等.

进程实体(也成为进程映像)由程序段,数据段,PCB三个部分构成.对于不同的角度,进程由不同的定义,比较典型的有:

* 进程是程序的一次执行过程
* 进程是一个程序及其数据在处理机上顺序执行时所发生的活动
* 进程是具有独立功能的程序在数据集合上运行的过程,它是系统进行资源分配和调度的一个独立单位.

不管哪种定义,都在强调进程的动态性

引入了进程实体后,还可以认为: 进程是进程实体的运行过程,是系统进行资源分配和调度的独立单位.不过进程实体是静态的.



**进程的组成**

进程一般指的是进程实体,它由程序段,数据段,PCB三个部分构成.

程序段是进程的程序代码,数据段是进程执行所需的数据,比如我们的变量啊常量啊对象啊等等东西.PCB它具体包含以下东西:

* 进程描述信息
  * 进程标识符(任务管理器里面的那个PID) : 唯一的,进程创建时由OS创建
  * 用户标识符(UID)
* 进程控制和管理信息
  * 进程当前状态
  * 进程优先级
* 资源分配清单
  * 程序段指针
  * 数据段指针
  * IO设备
* 处理机相关信息 : 这个是为了在进程切换的时候保存当前信息整的
  * 各种寄存器值

**进程在操作系统中的组织方式**

通常PCB的数量都很大,操作系统是如何组织这些进程(进程实体)的嘞:

* 链接方式

  * 按照进程状态将PCB分为多个队列
  * 操作系统持有指向各个队列的指针

  一般有这些队列 : 执行指针,就绪队列指针,阻塞队列指针.

* 索引方式

  * 根据进程状态的不同,建立索引表
  * 操作系统持有指向各个索引表的指针

  索引也是那三种指针,索引表里面就是对应状态的PCB

### 进程的状态与切换

进程的状态

* 运行 : 正在跑
* 就绪 : 缺处理机(CPU)
* 阻塞 : 因为在等待某些事件而不能运行(比如等IO操作完成)
* 创建 : 新进程需要被初始化空间(PCB,程序段和数据段的内存分配)此时就是在创建进程
* 终止 : 运行出Bug了,或者出异常了进程停止,操作系统会回收资源.此时进程就是在终止态

进程的状态转换

* 就绪->运行 : 等CPU
* 运行->就绪 : 失去CPU(比如时间片到了)
* 运行->阻塞 : 因为IO等中断事件阻塞了进行运行,资源和CPU被剥夺就阻塞了.一般是由进程主动进入的(也就是调用系统调用进入中断)
* 阻塞->就绪 : 阻塞事件结束,等待CPU继续跑

### 进程控制

进程控制是啥?

进程控制的主要功能是对系统中的所有进程实施有效的管理,它能够创建新线程,撤销已有进程,实现进程状态切换等功能.从简理解,进程控制就是实现进程状态的转换.

**进程控制的实现**

之前我们知道,系统管理进程是通过就绪队列和阻塞队列两个队列及其指针来管理在其中的PCB的,![进程控制流程](D:\C++学习笔记\OSpicture\进程控制流程.PNG)

这些蓝色的方块就是进程的PCB.

进程控制的实现是用**原语**实现的.原语的特点是运行期间是不可中断的,也就是说原语是一种原子操作.

原语采用关中断指令和开中断指令实现.这种指令是特权指令.

进程控制相关的原语:

* 更新PCB信息的原语
* 将PCB插入合适队列的原语
* 分配/回收资源的原语



## 进程通信

进程之间是需要进行信息传递和交换的.各个进程拥有内存的地址空间是互相独立的,一个进程是不可以去访问其他进程的地址空间的.那么进程之间的资源要如何实现共享嘞?这就需要操作系统提供的一些方法了:

* 共享存储

  操作系统会给进程分配一个共享空间,进程就可以通过这个共享空间来进行通信了.

  共享空间的访问和操作是互斥的.也就是说一个进程在读写这个空间的时候,另一个进程是不可以访问这个共享空间的.

  这个互斥访问操作是由操作系统提供的同步互斥工具实现的.

  * 基于数据结构

    就是在共享空间里只能放一个固定大小的数据结构,比如数组.这种通信方式的速度慢,限制多,是低级的通信方式

  * 基于存储区

    在内存种划分一块共享存储空间,数据的形式,存放位置都由进程来决定而不是操作系统.这种通信方式更加高效.是一种高级的通信方式.

* 消息传递

  进程间以格式化消息为单位的数据,通过操作系统提供的消息收发两个原语进行数据交换.格式化消息的结构由消息头和消息体组成

  * 消息头 : 包括进程ID,接受进程ID,消息类型,消息长度等信息.计算机网络中发送的报文就是一种格式化消息
  * 直接通信方式 : 消息直接挂到接受进程的消息缓冲队列上.
  * 间接通信方式 : 消息先发到中间实体中(信箱,计算机网络中的邮件系统),接收进程从信箱里拿.

* 管道传递

  管道是指用于连接读写进程的一个共享文件.又名pipe文件.其实就是在内存中开辟一个大小固定的缓冲区.管道一般与内存页面一样大

  * 管道只能采用半双工通信,也就是某一时间段内实现单向传输.如果要双向同时通信,需要设置两个管道
  * 各进程要互斥的访问管道,也就是同一时间只能有一个进程使用管道.
  * 数据要以字符流的形式写入管道,当管道写满了后,写进程的关于写入的系统调用会被阻塞,等待读进程间数据全部读走后,管道变空,读进程的读的系统调用被阻塞,然后写进程才可以继续向管道写入数据.
  * 管道中的数据一旦被读出,就相当于被管道抛弃,这就意味着一个管道的读进程最多只能有一个,否则会导致读错数据的情况.



## 线程与多线程

我们在一个进程中,是能够使用进程提供的很多功能的,比如QQ,我们可以发送信息,发视频,发语言等,也就是说,进程是需要同时做很多事的.而传统的进程只能串行地执行一系列的程序.为此引入了线程来增加程序的并发度.

传统的进程是程序执行流的最小单位.而引入了线程之后,程序执行流的最小单位就是线程了.也就是基本的CPU执行单元变成了线程.

引入了线程后,进程只作为除了CPU外的系统资源的分配单元,也就是内存,外设等东西是给进程的,而不是给线程.

引入线程后的变化

* 资源分配
  * 传统进程机制中,进程是资源的分配,调度的基本单位.
  * 引入线程后,进程是资源分配的基本单位,线程是调度的基本单位
* 并发性
  * 传统进程中,只能进程间并发
  * 引入线程后,各线程之间也能并发.提升了系统的并发度
* 系统开销
  * 传统进程间的并发需要切换进程的运行环境,系统开销大
  * 线程间并发,如果是同一进程内的线程切换,就不需要切换进程环境,开销小

**线程的属性**

* 线程是CPU调度的基本单位
* 多核CPU中,各个线程可以占用不同CPU核心
* 每个线程都有一个线程ID,线程控制块TCB
* 线程也有就绪,运行,阻塞三种基本状态
* 线程几乎不拥有系统资源
* 同一进程的不同线程间共享进程的资源
* 同一进程中的线程间通信无需操作系统干预
* 同一进程中的线程切换,不会影响进程信息
* 不同进程中的线程切换会引起进程切换
* 切换同进程内的线程,系统开销小
* 切换进程系统开销大

**线程的实现**

* 用户级线程

  用户级线程由应用程序通过线程库实现.所有的线程管理工作都由应用程序负责(包括线程切换),用户级线程中,线程切换可以在用户态下即可完成,无需操作系统干预.操作系统是看不到线程的,但是用户可以感受到.

* 内核级线程

  又称内核支持线程.内核级线程的管理工作由操作系统内核完成.因此内核级线程的切换必须在核心态下完成.内核级线程才是操作系统能看到的线程.而这个线程是用户看不见的.

对于这两种级别的线程.只有内核级线程才是操作系统能看到的,所以只有内核级线程才是CPU分配的单位.平时我们的用户级线程的调度是因为通过线程库映射到了内核级线程才能实现调度的.

**多线程模型**

几个用户级线程映射到几个内核级线程衍生出了: 多线程模型问题

* 多对一模型 : 多个用户级线程映射到一个内核级线程上.每个用户进程只对应一个内核级线程
  * 这个模型下,用户级线程的切换在用户空间即可完成,不需要切换到核心态,线程管理的系统开销小,效率高
  * 但是当一个用户线程阻塞后,整个进程都会被阻塞.并发度不高.多个线程不可在多核CPU上并行运行.
* 一对一模型 : 一个用户线程对应一个内核级线程,相当于完全使用内核级线程
  * 这个模型下,一个线程被阻塞是不会影响其他线程的,并发能力强,并且可以在多核CPU上并行执行
  * 因为用内核线程,所以要在核心态下进行切换状态,系统开销比较大
* 多对多模型 : n个用户线程映射到m个内核线程上(n>=m).
  * 这个模型下,它可以避免多对一模型下的并发量小的缺点以及一对一模型的大系统开销的问题.



## 处理机调度

调度 : 即因为资源有限的问题,多个任务需要根据某种规则来决定处理的顺序,调度就是决定任务处理的顺序的.

在多道程序系统中,进程的数量往往远大于处理机数量,处理机调度就是从任务队列中按照一定的算法来对任务进行顺序处理

**调度的层次**

* 高级调度

  又称作业调度.按一定原则从外存(硬盘)上处于后备队列的作业中选择一个或多个作业给他们分配内存等必要资源,并建立相应的进程(PCB),以使它们获得竞争处理机的权利.

  高级调度是外存于内存之间的调度.每个作业只调入一次调出一次.作业调入时会建立相应进程,作业调出时才撤销进程.高级调度主要指调入的问题,因为只有调入的时机需要操作系统来决定,但调出肯定是在作业执行完毕后才调出

* 中级调度

  有了虚拟存储技术后,可以将暂时不能运行的进程调到外存等待.等它重新具备条件后而且内存有空闲时才会把它调入内存.这么做是为了提高内存利用率和系统吞吐量.

  暂时调到外存等待的进程状态为挂起状态.但是进程调出到外存的时候,PCB并不会一起被调出去,而是常驻于内存,PCB会存在于操作系统创建的挂起队列中.

  中级调度也称内存调度,它就是决定将哪个挂起进程重新调入内存的,它是可能发生多次的.

  * 挂起状态和七状态模型

    我们之前的进程状态只有五种 : 创建,就绪,运行,阻塞,终止

    而有了中级调度,有增加了两种挂起态 : 就绪挂起,阻塞挂起

    就绪挂起 : 但内存不够了,在就绪态的进程可能就仍到外存去了,如果内存够了就读回来.运行态的进程失去处理机并且内存不够时也可能直接变成就绪挂起态.创建态的进程因为内存不够也可能直接变成就绪挂起态.

    阻塞挂起 : 跟就绪挂起态条件差不多.但是当事件发生时,阻塞挂起态可被转换成就绪挂起态,并且在内存足够时直接变成就绪态.它也可能直接回到阻塞态

* 低级调度

  也称进程调度,它主要的任务是按照某种方法和策略从就绪队列中选取一个进程,将处理机分配给它.

  低级调度是操作系统中最基本的一种调度,在一般的操作系统中必须实现低级调度.它的调度频率很高,一般几十毫秒就调度一次,因为要实现并行.

**进程调度的时机**

就是低级调度.

* 当前运行的进程主动放弃处理机 : 正常终止,程序异常,主动请求阻塞等
* 当前运行的进程被迫放弃处理机 : 时间片用完,有更高优先级的进程进入就绪队列,有更紧急的事(中断了)

有时候是不可以进行进程调度的

* 在处理中断的时候是不能进行进程调度的
* 在原子操作的过程中也不行
* 进程在操作系统内核程序的临界区中的时候
  * 临界资源 : 互斥资源,即不可同时被多个进程同时使用的资源.
  * 临界区 : 访问临界区的代码
  * 内核程序临界区 : 一般是用来访问某种内核数据结构的,比如进程的就绪队列.
  * 对于内核临界区的那些内核临界资源如果不尽快释放,极有可能影响到内核的其他工作.此时就该快去释放内核临界资源,不该去进行进程调度.
  * 对于普通临界区来说,普通临界资源的回收前会导致进程的等待,此时CPU是空闲的,应该去进行进程调度

**进程调度的切换和过程**

狭义的进程调度 : 从就绪队列中挑一个要运行的进程.

进程调度 : 一个进程让出处理机,由另一个进程占用的过程

广义的进程调度 : 包含前两个过程.

进程的切换过程主要完成以下任务 : 

* 对原来运行进程的数据保存
* 对新的进程各种数据的恢复



**进程调度的方式**

* 非剥夺调度

  又称非抢占式调度,只允许进程主动放弃处理机,然后再去执行其他任务

* 剥夺调度

  又称抢占式调度,当有更紧急的任务的时候,就立刻停止现在的,先去处理那个紧急任务



**调度算法的评价标准**

* CPU利用率

  指的是CPU工作状态占总时长的比例,也就是CPU利用率 = CPU忙碌时间/总时长

* 系统吞吐量

  单位时间内完成作业的数量. 系统吞吐量 = 总共完成的作业数量 / 总时长

* 周转时间

  指作业被提交给系统开始到作业完成为止的这段时间间隔.它包括四个部分

  * 作业在外存等待高级调度的时间
  * 进程在就绪队列等待进程调度的时间
  * 进程在CPU上的执行时间
  * 等待IO操作完成的时间.

  后面三项在一个作业的处理过程中可能发生多次.

  周转时间 = 作业完成时间 - 作业提交时间

  平均周转时间 = 各个作业周转时间总和 / 作业数量

  带权周转时间 = 周转时间/作业时机运行时间

  平均带权周转时间 = 各个作业的带权周转时间/作业数量

* 等待时间

  指进程处于等待处理机状态时间的和,也就是上面周转时间中除了进程在CPU上的执行时间和等待IO时间外的时间的和.

* 响应时间

  指的是用户提交请求到首次产生响应所用的时间

**调度算法**

* 先来先服务FCFS
  * 算法思想 : 从公平角度出发
  * 算法规则 : 按照进程到达的先后顺序进行服务
  * 应用 : 用于作业调度时,考虑的是作业到达后备队列的先后顺序.用于进程调度是,考虑的是进程进入就绪队列的先后顺序.
  * 抢占式/非抢占式 : FCFS是一个非抢占式的算法
  * 是否会导致饥饿(一个进程长期得不到服务) : 不会的,因为所有任务的都会执行完.
  
* 最短作业优先SJF
  * 算法思想 : 追求最少的平均等待时间,最少平均周转时间,最少平均带权周转时间
  * 算法规则 : 最短作业/进程优先得到服务.每次调度时选择当前已经到达且运行时间最短的作业/进程.
  * 应用 : 可用于作业调度,也可用于进程调度.用于进程调度时称为短进程优先算法.
  * 抢占式/非抢占式 : 有抢占式.如果是抢占式的话,每当有进程加入就绪队列时就会进行调度,如果新到达的进程的剩余时间比当前运行的进程的剩余时间更短,那么这个新进程就会获得处理机,当前在运行的进程进入就绪队列等待.此外,当一个进程完成时也需要调度.
  * 是否会导致饥饿 : 可能会导致长作业饥饿,比如很多短作业不断加入就绪队列的时候就会导致这种情况,甚至可能导致进程饿死.
  
* 最高相应比优先HRRN

  * 算法思想 : 综合考虑作业/进程的等待时间和要求服务的时间

  * 算法规则 : 在每次调度时先计算各个作业/进程的响应比,选择响应比最高的作业/进程为其服务.

    响应比 = (等待时间+要求服务时间)/要求服务时间

  * 应用 :又可以用于作业调度,也可以用作进程调度

  * 抢占/非抢占 : 非抢占的,只有在一个作业主动放弃处理机的时候才会触发调度.

  * 是否会导致饥饿 : 不会

* 时间片轮转调度RR
  * 算法思想 : 公平,轮流的为各个进程服务,让每个进程在一定时间间隔内都可以得到响应
  * 算法规则 : 操作系统按照进程到达就绪队列的顺序,轮流让各个进程执行一个时间片(比如100ms),当一个进程在一个时间片内没有处理完,时间片到时后就强行剥夺处理机,进程重新排队
  * 应用 : 用于进程调度,因为只有作业放入内存建立了进程才可以被分配时间片
  * 抢占/非抢占 : 抢占式的.由时钟装置发出的时钟中断信号来通知CPU时间片到时了
  * 是否会导致饥饿 : 并不会

* 优先级调度
  * 算法思想 : 按照任务的紧急程度,也就是优先级来决定处理进程的顺序
  * 算法规则 : 作业/进程有自己的优先级,按高优先级先调度的规则
  * 应用 : 作业调度/进程调度.IO调度也行.
  * 抢占/非抢占 : 有抢占式的也有非抢占式的.
  * 是否会导致饥饿 : 有可能,低优先级的任务可能长时间得不到处理.
  * 对于优先级来说,操作系统是偏向于IO密集型进程的,为啥嘞?因为IO设备和CPU可以并行工作,如果优先让IO密集型进程优先运行,就可以越早让IO设备投入工作,则资源利用率,系统吞吐量都会有一定提高

* 多级反馈队列调度
  * 算法思想 : 对以上所有算法的折中权衡
  * 算法规则 : 
    * 设置多级就绪队列,各级队列优先级从高到低,时间片从小到大
    * 新进程到达时先进入第一级队列.按FCFS原则排队等待被分配时间片,若用完时间片进程还未结束,则进程进入下一级队列队尾.如果此时已经在最下级的队列中,就重新放回该队列队尾.
    * 只有第k级队列为空时,才会为k+1级队列头的进程分配时间片
  * 应用 : 进程调度
  * 抢占/非抢占 : 是抢占的
  * 是否会导致饥饿 : 当有优先级高的,处理时间短的进程不断进入队列时,已经被降级的进程可能就得不到处理.所以是可能会导致饥饿的

### 进程同步/互斥

**进程同步**

同步是一种直接制约关系,它是指为完成某种任务而建立的两个或多个进程,这些进程因为需要在某些位置上协调它们的**工作次序**而产生的制约关系.进程间的直接制约关系就是源于它们之间的相互合作.

也就是谁应该先执行,谁应该后执行

**进程互斥**

进程在并发的时候因为存在资源的共享.进程互斥就是指当一个进程访问某临界资源的时候,另一个想访问这个临界资源的进程必须等待.对临界区的互斥访问,可以在逻辑上分为以下四个部分 :

```c
do{
    entry section;//进入区 : 负责检查是否可以进入临界区,如果可以,就设置一个锁,以阻止其他进程进入临界区
    critical section;//临界区/段 : 访问临界资源的代码
    exit section;//退出区 : 解锁
    remainder section;//剩余区 : 做其他处理
}while(true)
```

为了实现对临界资源的互斥访问,同时保证整体性能,临界区需要遵循以下原则:

* 空闲让进 
* 忙则等待
* 有限等待
* 让权等待

**进程互斥的软件实现方法**

* 单标志法

  * 算法思想 : 两个进程在访问临界区后会把使用临界区的权限转给另一个进程,也就是每个进程进入临界区的权限是由另一个进程赋予的.

    ```c
    int turn = 0;//表示当前允许进入临界区的进程号
    //p0进程
    while(turn != 0);//进入区
    critial section;//临界区
    turn = 1;//退出区
    remainder section;//剩余区
    //p1进程
    while(turn != 1);
    critial section;
    turn = 0;
    remainder section;
    //当p0先进入了临界区,那么此时p1进入CPU的时候就会卡在while语句.直到回到p0,并且p0解锁后,p1才可以进入临界区
    ```

    该方法违背了 空闲让进 的原则

* 双标志先检查

  * 算法思想 : 设置一个bool数组,数组中的元素用来标记各个进程想进入临界区的意愿,比如flag[0]=true就表示进程0想进入临界区.每个进程在进入临界区之前先检查当前有没有其他进程要进入临界区,没有的话就把自己标记为true,然后开始访问临界区

    ```c
    bool flag[2];
    flag[0] = false;
    flag[1] = false;
    //p0
    while(flag[1]);
    flag[0] = true;
    critical section;
    flag[0] = false;
    remainder section;
    //p1
    while(flag[0]);
    flag[1] = true;
    critical section;
    flag[1] = false;
    remainder section;
    ```

    如果进程在并发的话,可能会导致多个进程可以进入临界区,导致临界资源出问题.

    该方法违背了 忙则等待 的原则.因为这里的检查和上锁并不是一个原子操作.

* 双标志后检查

  双标志先检查的改进版.就是先上锁再检查.

  但在并发的时候,可能会导致所有进程没法进入临界区.导致进程长时间阻塞,发生死锁.

  这个方法违背了 空闲让进和有限等待 的原则.

* Peterson算法

  进程礼让,当两个进程都想进临界区,当前线程可以尝试礼让临界资源.

  ```c
  bool flag[2];
  int turn = 0;
  //p0
  flag[0] = true;
  trun = 1;
  while(flag[1] && turn == 1);
  critical section;
  flag[0] = false;
  remainder section;
  //p1
  flag[1] = true;//我想进临界区
  turn = 0;//可以优先让对方进入临界区
  while(flag[0] && turn == 0);//对方想进,且最后一次是自己礼让,那自己就等着
  critical section;
  flag[1] = false;//自己访问完了.
  remainder section;
  ```

  本方法违背了 让权等待 的原则.

**进程互斥的硬件解决方法**

* 中断屏蔽

  利用开关中断指令实现.

* TestAndSet(TS指令/TSL指令)

* Swap指令



## 信号量机制

用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作,从而很方便的实现进程互斥,进程同步.

信号量其实就是一种变量(可以是一个整数,也可以是更复杂的记录型信号量).可以用一个信号量来表示系统中某种资源的数量,比如系统中有一台打印机,就可以设置一个初值为1的信号量.

wait(S)原语和signal(S)原语就是操作系统给我们提供的信号量操作原语.我们可以认为它就是个函数,wait和signal是函数名,信号量S就是函数参数.这两个原语也称为PV操作.所以也可以写为P(S)和V(S).

**整型信号量**

用一个整数型的变量来表示系统中某种资源的数量.这种用作信号量的整型变量.只能用作三种操作 : 初始化,P操作,V操作.

```c
int S = 1;//表示一个系统资源
void wait(int S){//wait原语,相当于进入区
    while(S <= 0);//资源不足,等
    S = S - 1;//够了就占用一个资源
}
void signal(int S){//signal原语,相当于退出区
    S = S + 1;//使用完资源,放回去.
}
```

```c
//进程p0
wait(S);//进入区,申请资源,因为wait和signal是原语, 所以不会因为进程切换导致问题.但也存在一点问题,也就是因为原语中的循环会导致无法中断.
临界区;
signal(S);//退出区,释放资源
//进程p1
wait(S);
临界区;
signal(S);
```





**记录型信号量**

 该类型的信号量是为了解决整型信号量的忙等问题的.

```c
typedef struct{
    //记录型信号量的定义
    int value;//剩余资源数
    struct process *L;//等待队列
}semaphore;
```

```c
void wait(semaphore S){
    S.value--;
    if(S.value < 0){
		block(S.L);//block原语的作用是为了阻塞当前进程,因为资源不足.并把它挂到信号量S的阻塞队列中.
    }
}
void signal(semaphore S){
	S.value++;
    if(S.value < 0){
        wakeup(S.L);//释放资源后,如果还有别的进程在等待资源,就用wakeup原语唤醒阻塞队列中的进程
    }
}
```

**信号量实现进程互斥,同步,前驱**

信号量其实就是一种锁的实现机制.在线程中的锁也同样适用.

互斥的实现 : 

* 先划定临界区(找到进程处理临界资源的代码区域)

* 设置互斥信号量mutex,初始值为1.

  ```c
  samphore mutex = 1;//初始化信号量
  P1(){
      //P1进程
      P(mutex);//P操作,加锁
      //临界区代码
      V(mutex);//V操作,释放锁
  }
  //...其他进程也是这个模式
  ```

* 在临界区前执行P操作:P(mutex);

* 在临界区后执行V操作:V(mutex);

* 对于不同的临界资源设置不同的互斥信号量.也就是多个samphore类型的变量.

同步的实现 :

因为同步是要求进程按要求有序的推进.但因为异步性,多个进程交替推进的次序是不确定的.

* 分析需要实现同步关系的地方,也就是需要保证运行次序的操作位置

* 设置同步信号量S,初值为0

  ```c
  semaphore S = 0;//初始化同步信号量
  
  //p1
  p1(){
      code1;
      code2;
      V(S);
      code3;//需要先执行的操作
  }
  P2(){
      P(S);
      code4;//需要后执行的操作.
      code5;
      code6;
  }
  ```

* 在应该首先执行的位置之后执行V(S)操作

* 在应该后执行的位置之前执行P(S)操作

前驱的实现:

前驱 : 就是进程中的代码需要根据一定的次序来执行. 是一种多层的同步问题,就是一个树形结构的同步顺序.

对于这种问题,可以为每一个前驱关系设置一个同步信号量.然后:

* 在应该先执行的操作后进行V操作
* 在应该后执行的操作前进行P操作

就OK了.



**生产者消费者问题**

生产者消费者问题与进程中是一样的.

在系统中有一组生产者进程和一组消费者进程,生产者进程每次生产一个产品放入缓冲区,消费者每次从缓冲区中取出一个产品并使用.这个产品就是各种数据.

只有缓存区没满的时候,生产者才可以把产品放入缓冲区中,否则必须等待. : 也就是说,对缓冲区的访问是互斥的

也就是缓冲区满的话必须要消费者消费掉,产生空余了,生产者进程才会回到就绪态. : 生产者和消费者之间是同步的.

对于消费者进程来说,只有缓冲区中有产品,才可以进行消费行为,否则必须等待.: 对缓冲区的访问是互斥的

缓冲区是一种临界资源.各进程必须互斥的进行访问.因为并发情况下可能会导致产品覆盖和重复取同一产品的问题.

生产者消费者问题就是一种进程同步互斥问题.可以很容易的使用信号量机制来解决(也就是通过PV操作),在确定各个进程的同步和互斥关系后,就可以很容易做出对应操作.对于PV操作,它们之间是有顺序要求的.如果顺序不正确,可能就会导致死锁.所以实现互斥的P操作,必须要在实现同步的P操作之后.而V操作是不会导致死锁的,V操作的顺序可以随意.而对于非临界区的代码,可以随便放,但是建议不要放在临界区里,这会导致处理时间变多.

**多生产者多消费者问题**

也就是多个线程生产不同的产品,多个线程也消费不同的产品.

对于这样的问题,所以对于一类产品,生产者和消费者之间是互为同步的 : 生产者对消费者是同步,消费者对于生产者也是同步.

**吸烟者问题**

假设一个系统有三个抽烟者进程和一个供应者进程,抽烟者会卷烟并消耗掉这个烟.但是要卷烟需要三个材料 : 烟草,纸,胶水.每个抽烟者都只持有一种材料.而供应者可以提供三种材料,供应者每次提供两种材料,放到桌子上,拥有剩下一种材料的抽烟者会获取材料并卷烟消耗掉烟,并给供应者一个信号告诉它完成了.供应者会放另外两种材料到桌上,这个过程一直重复.这个问题也是一种消费者问题.

在这个问题中,有四个进程,对于缓冲区来说,每个进程都是互斥访问缓冲区的.

同步问题 : 1.当桌上有消费进程1需要的东西时,消费进程1才会取走东西,对于其他两个进程也是同理.

​					2.当一个消费进程消费完成,就通知生产者生产产品.

所以设置一个互斥信号量和4个同步信号量即可解决该问题的互斥同步问题.

**读者-写者问题**

一个系统中,有一组读进程和一组写进程.当两个或两个以上的读进程同时访问共享数据时不会产生副作用,但是如果某个写进程和其他进程同时访问共享数据时则可能导致数据不一致问题.因此要求 : 1.允许多个读进程同时读文件,2.只允许一个写进程向共享文件写入信息.3.任意写进程完成写操作前不允许其他读写进程进行操作.4.写进程执行写操作时,应该让正在读的进程和写的进程退出.

这个问题中的互斥同步关系 : 

互斥  : 写进程和写进程之间,写进程和读进程之间

读进程与读进程之间是允许并发的,也就是允许同时读共享文件.如果每个进程都要上锁的话,显然不能达到这个要求,所以我们可以加一个计量值,来记录读进程的数量.只让第一个开始读的进程上锁,最后一个读完的进程解锁.在这个过程中需要判断,但是在判断的时候如果切换进程,是可能导致多个读进程没法并发的.所以我们可以用一个互斥信号量来给这个判断总量进行上锁.但如果读进程源源不断的进来,可能会导致写进程饿死.因为在这个时候我们默认是读进程优先的,所以我们可以增加一个互斥信号量,用来给读进程和写进程的互斥.

```c
semaphore rw = 1;//实现进程对共享文件的互斥访问
int count = 0;//记录读进程数量
semaphore mutex = 1;//保证对count变量的互斥访问
semaphore w = 1;//保证写进程优先
//读进程
reader(){
    while(1){
        P(w);
        P(mutex);
        if(count == 0) P(rw);
        count ++;
        V(mutex);
        V(w);
        //读操作
        P(mutex);
        count --;
        if(count == 0) V(rw);
        V(mutex);
    }
}
//写进程
writer(){
    while(1){
        P(w);
        P(rw);
        //写文件
        V(rw);
        V(w);
    }
}
```

这种方式也称作读写公平法.

同步 : 这里没有同步的要求.

**哲学家进餐问题**

在一个圆桌上,周围有5个哲学家,桌子中间是一大锅饭,每个哲学家之间是一根筷子.哲学家们用毕生的精力来思考和进餐,当哲学家在思考的时候,并不会影响他人,当哲学家饥饿的时候,才会视图拿起左右两边的筷子(一左一右一根一根的拿起),如果筷子已经在其他人受伤,就需要等待.只有在同时拿起两根筷子的时候才可以吃饭,当吃完后就放下筷子继续思考.

本题目共有5个进程,其中的互斥和同步关系:
互斥 : 5个进程与左右邻居对其中间的筷子的访问是互斥的

本问题中没有同步关系的存在.对于每个哲学家进程来说,需要同时获取到一左一右两个临界资源才可以吃饭.主要的问题就是如何避免临界资源分配不当导致死锁问题.

解决办法 : 用一个互斥信号量数组 : chopstick[5] = {1,1,1,1,1}.来表示五个筷子

```c
sempaphore chopstick[5] = {1,1,1,1,1};
//pi : 第i个哲学家
pi(){
    while(1){
        //如果对每个进程都设置互斥的话,如果每个进程都获取了一个临界资源,就会导致第二个临界资源的获取阻塞,并导致死锁.
        //解决这个问题的方法:
        //1.只允许最多4个进程同时运行,这样就可以保证有一个进程能够运行,而不会导致死锁.
        //2.要求奇数编号的进程先拿左边的资源,然后再拿右边的资源,而偶数编号的进程相反.这种方式可以保证如果相邻的奇偶编号的进程都想运行的话,就只有一个能够获取到它们之间的临界资源.另一个会阻塞,这就避免了一个进程占有资源后另一个进程等待另一个进程...这样的死锁问题.
        //3.仅当一个进程左右两个临界资源都获取到的时候才能运行.
    }
}
```



### 管程

信号量机制存在一定的问题 : 编写程序麻烦,容易出错误.比如PV操作的顺序就可能会导致死锁.

管程是一种高级的同步机制.它在1973年提出.

管程 : 它是一种特殊的软件模块,由这些部分组成:

* 局部于管程的共享数据结构说明(比如生产者消费者的缓存区)
* 对该数据结构进行操作的一组过程(也就是操作,比如编程语言中的函数,方法),也就是提供对外访问接口.
* 对局部于管程的共享数据设置初始值的语句.
* 管程有一个名字

看了上面的东西,是不是感觉很像类这种东西嘞.

管程的特征 : 

* 局部于管程的数据只能被局部于管程的过程所访问
* 一个进程只有通过调用管程内的过程才可以进入管程访问共享数据
* 每次仅允许一个进程在管程内执行某个内部过程.

我们用伪代码来表示管程解决生产者消费者的过程 : 

```txt
monitor ProducerConsumer //ProducerConsumer表示管程的名字,前面的东西表示某个语言提供的关于管程的定义关键字
	condition full,empty;//条件变量,用于实现同步
	int count = 0;//缓冲区中的产品数
	void insert(Item item){
		//把产品item放入缓冲区
		if(count == N){
			wait(full);
		}
		count++;
		insert_item(item);
		if(count == 1){
			signal(empty);
		}
	}
	Item remove(){
		//从缓冲区取出一个产品
		if(count == 0){
			wait(empty);
		}
		count--;
		if(count == N - 1){
			signal(full);
		}
		return remove_item();
	}
end monitor;
```

在管程中,由编译器负责实现各个进程互斥地进入管程中的进程.程序员不需要关心如何实现进程的互斥,同步.

Java中提供的synchronized来描述一个函数的时候,这个函数就只能在同一时间内被一个线程调用.也就是Java的锁机制就是管程的一种实现.



### 死锁

死锁在之前的进程互斥同步问题中已经提高过,死锁就是进程之间循环等待其他进程释放所需临界资源的情况.发生死锁后,如果没有外部干涉,这些进程就没法向前推进.

死锁,饥饿,死循环的区别 : 饥饿是线程长时间得不到处理机导致的问题.死循环是程序的逻辑或者程序实现需要而产生的.它们都是一种进程无法推进的情况.死锁最少需要两个进程以上产生的结果,而饥饿一般就只有一个进程.死循环是由被管理者所控制的,死锁和饥饿问题是管理者导致的,也就是操作系统所产生的问题.

**死锁产生的必须条件**

* 互斥条件 : 并发的进程必须是对互斥的资源的争夺才会导致死锁
* 不可剥夺条件 : 进程所获取的资源在未使用完前不能由其他进程夺取,只能等待主动释放.
* 请求和保持条件 : 进程已经保持了至少一个资源,但是又提出了其他资源的请求,而该资源被其他进程占有,此时进程阻塞但又不释放自己所持有的资源.
* 循环等待条件 : 存在进程资源的循环等待链,链中的每一个进程已经获得的资源同时被其他进程请求.

发生死锁的时候必存在循环等待,但是存在循环等待的时候未必是发生了死锁.也就是说,循环等待条件是死锁的必要不充分条件.

由上述条件,死锁一般就会发生在这些情况下 :

1.对系统互斥资源的争夺

2.进程推进顺序非法,请求和释放资源的顺序不但,也是可能会导致死锁的.

3.信号量使用不当也可能造成死锁.

总之就是对互斥资源的分配不合理就可能导致死锁.

**死锁的处理策略**

* 预防死锁 : 破坏产生死锁四条件中的一条即可防止死锁的产生

  * 破坏互斥条件 : 可以把互斥资源变为共享资源,那么进程就不会因为资源的互斥而产生互斥条件.但为了系统安全,互斥性是很难去改变的.
  * 破坏不可剥夺条件 : 当进程请求新的互斥资源但没有响应的时候,就释放自己的资源,等以后需要的时候再重新申请.就可以破坏不可剥夺条件.或者将需要请求的资源由操作系统协助把需要的互斥资源从其他进程强行剥夺.也可以破坏不可剥夺条件.但是这种方法的实现比较复杂.并且强行释放资源的话,有可能会导致进程的工作进度丢失.所以本方法一般只适用于容易保存和容易恢复状态的资源.资源的申请和释放会消耗系统资源,也会降低系统的吞吐量
  * 破坏请求和保持条件 : 可以采用静态分配方法,也就是在进程运行前申请完它需要的全部资源,在资源不满足该线程运行时,就不运行.一旦投入运行,进程就不会请求别的资源了.但这个方法的话可能会在运行的时候占用所有资源,资源利用率就会降低,系统资源也得不到有效的利用.此外,还可能会导致进程饥饿.
  * 破坏循环等待条件 : 可以采用顺序资源分配法,就是给系统中的资源进行编号,规定每个进程必须按编号递增的顺序请求资源,同类资源(编号相同的资源)一次申请完.[也就是拥有小编号资源的进程有权申请大编号资源,而持有大编号资源的进程是不可以来申请小编号的,所以不会产生循环等待条件].使用该方法的话,就会导致新增互斥资源比较麻烦,而且进程实际使用资源的顺序可能和编号递增顺序不一样,会导致资源浪费.因为要按次序申请资源,编程实现会比较麻烦.

* 避免死锁 : 用某种方法防止系统进入不安全状态,从而避免死锁,比如银行家算法

  * 安全序列 : 也就是系统按安全序列的顺序给进程分配资源,每个资源就可以顺序完成执行.所以只需要找到安全序列,系统就是安全状态,安全序列可以是不唯一的.

    如果分配资源后,找不到安全序列的话,系统就进入不安全状态,这就意味着进程可能没法顺利执行,但后序如果由进程提前归还了资源,那系统可能重新回到安全状态.

    如果系统处于安全状态,就一定不会发生死锁,如果系统进入不安全状态,就可能会产生死锁.

    因此在资源分配前预先判断此次分配是否会导致系统进入不安全状态,以此决定是否打印分配请求,这就是银行家算法的核心思想

* 死锁的检测和接触 : 允许死锁的发生,操作系统会负责检测死锁的发生并能够采取某种策略接触死锁.

  要使系统能够对是否已发生死锁进行检测,必须能够:

  * 用某种数据结构来保存资源的请求和分配信息
    * 比如资源分配图这种数据结构:
      * 资源分配图(两种结点+两种边)
        * 进程结点 : 对应一个进程
        * 资源结点 : 对应一类资源,一类资源可能有多个
        * 进程结点-->资源结点 : 表示进程想申请几个资源(每条边代表一个)
        * 资源结点-->进程结点 : 表示已经未进程分配了几个资源(每条边代表一个)
  * 提供某种算法,利用以上信息来检测系统是否进入死锁状态.

  当系统中剩余的可用资源数足够满足进程的需求,那么这个进程暂时不会阻塞,可顺利执行.如果顺利运行的进程运行完成并归还资源给系统,就可能使某些正在等待资源的进程被激活,并给它们分配资源以使它们顺利运行.此时资源分配图的所有边是可用完全消除的.

  当分配的边最终无法消除时,就意味着此时产生了死锁.此时未消除边的进程结点就是发生了死锁的进程.

  * 检测死锁的算法:

    在资源分配图中,找出既不是阻塞,又不是孤点(有一条有向边与它相连,并且该有向边对应资源的申请数量小于等于系统中存在的空闲资源数量)的进程,小区它所有的请求边和分配边,使之变为孤立的节点.然后由上面那个进程所释放的资源可用唤醒某些因等待这些资源而阻塞的进程,原来的阻塞进程可能变为非阻塞进程.在这个过程中如果能消除途中的所有边,则称该图是可完全简化的.此时是不会发生死锁的.当边没法消除的时候才会发生死锁,这也是死锁定理的含义(某时刻系统的资源分配图是不可完全简化的,此时系统存在死锁)

  * 死锁的接触方法

    当检测出了死锁,就需要把死锁解除掉.

    * 资源剥夺法 : 挂起某些死锁进程,并抢占它的资源,将这些资源分配给其他死锁进程,让它们运行下去,但是那个被挂起的进程可能会饥饿
    * 撤销进程法(终止进程) : 直接撤销部分或者全部的死锁进程,并剥夺这些进程的资源.但是这么做的代价比较大
    * 进程回退法 : 让一个或多个死锁进程回退到足以比界面死锁的地步,此时就需要系统记录进程的历史信息,并设置还原点.

  

  ## 内存管理

  ### 内存

  内存是用于存放数据的硬件,程序执行前需要先存放在内存中才能被CPU处理.
  
  #### 内存的组成
  
  内存是由一个个存储单元构成的,而一个个存储单元是有对应的地址的.存储单元的大小由计算机的编址方式,按字节编址的话那一个存储单元是1字节,也就是8位二进制数.也有计算机是按字编址的.
  
  CPU操作数据的时候,就根据每一个存储单元的存储地址去寻找对应的地址.并拿出来进行操作.我们实际的程序生成的指令是逻辑地址(相对地址).
  
  程序到程序运行的过程中的地址变化:
  源代码文件编译成模块的时候,比如.c文件编译成.o文件的时候,.o文件中的东西是按逻辑地址来分配的,每一个模块文件它们的逻辑地址起始都是0,然后再通过链接成.exe可执行文件时,每个模块的地址会统一,这个.exe文件的逻辑地址是由模块文件的所有地址合并成一共完整的逻辑地址的,然后把这个.exe文件的地址放到内存中对应地址上的位置,CPU就可以执行这个程序了.
  
  这个转入内存的过程由三种方式:
  
  * 绝对转入 : 在编译时就直到程序将放入内存中的绝对地址,编译程序就将产生绝对地址的目标代码.装入程序按照装入模块中的地址,将程序和数据装入内存.(转入模块就是.exe可执行文件)
  * 静态重定位  : 又称为可重定位装入.编译,链接后的装入模块的地址都是从0开始,指令中使用的地址,数据存放的地址都是相对于起始地址而言的逻辑地址,根据内存的当前情况,将装入模块装入到内存适当的位置.装入时对地址进行重定位,将逻辑地址转变为物理地址.这种方式的装入,必须要保证内存有足够的内存,否则就不能装载这个程序,而且装入后运行期间就不能再移动,也不可以再申请内存空间.
  * 动态重定位 : 又称动态运行时装入.这种方式的装入模块中的地址也使用的是逻辑地址,这个装入模块就算装入内存后,也不会立刻把逻辑地址变为物理地址,而是把这个过程推迟到了程序运行时才进行.这种方式需要重定位寄存器的支持.重定位寄存器是存储装入模块存放的起始地址.采用这种装入方式允许程序在运行时在内存中发生移动,以及允许程序可分配在不连续的存储区中.
  
  链接也有三种方式 : 
  
  * 静态链接 :程序允许前先将各目标模块以及它们所需的库函数链接成一个完整的装入模块,之后不再拆开.
  * 装入时动态链接 : 将各目标模块装入内存时,边装入边链接的链接方式
  * 运行时动态链接 : 在程序运行中需要该目标模块时,才会对它进行连接,这种方式便于对模块进行修改和更新,便于实现对目标模块的共享.
  
  ### 内存管理
  
  操作系统作为系统资源的最终管理者,内存也是它管理的一部分.
  
  操作系统的内存管理需要实现的功能:
  
  * 内存空间的分配和回收
  
    * 连续分配管理方式
  
      * 单一连续分配
  
        该分配方式下,内存被分为系统区和用户区,系统区一般处于内存低地址部分,其他是用户区.此时内存中只有一道用户程序.
  
      * 固定分区分配
  
        * 分区大小相等 : 将用户区分为大小相等的一些区域,每个区域装一个进程
        * 分区大小不等 : 按进程大小进行分区
  
      * 动态分区分配
  
        又称可变分区分配,这种分配方式不会预先划分内存区域,而是在程序装入内存时根据进程大小动态的建立分区,使分区刚好满足进程需要.此时分区和数目是可变的.
  
        操作系统会使用空闲分区表或者空闲分区链(双向链表)的形式来记录内存的使用情况.而空闲内存的分配是根据动态分区分配算法(常见的有四种,自己伯度)进行分配的.空闲内存的分配和回收会在记录空闲内存表上进行表现.
  
    * 非连续分配管理方式
  
      连续分配的管理方式有各种各样的缺点,这些缺点都是因为进程需要一整块连续空间的缘故.如果能实现进程拆分成几个部分去放到内存,内存的利用率就会++++.
  
      * 基本分页存储
  
        分页就是把内存分为一个个相等的,很小的小分区,再按照分区大小把进程拆分成一个个小部分.给这些小部分进行分配内存.这些小分区就是一共**页框**(页帧,内存块),每个页框都有一个编号,页框号从0开始.将用户进程的地址空间也分为与页框大小相等的一个个区域,称为**页**(页面),页也有页号为编号,也是从0开始.
  
        在这个过程中,对于逻辑地址的转换要这么操作 :
  
        * 要知道逻辑地址对应的页号
        * 要知道该页面对应页面在内存中的起始地址
        * 要算出逻辑地址在页面中的偏移量
        * 物理地址就是页面起始地址 + 页面内偏移量.
  
        实现上述逻辑的东西叫做基本地址变换机构,它是实现逻辑地址到物理地址转换的一组硬件机构.这种玩意有各种变种实现,比如具有块表的地址变换机构(快表(联想存储器),它是一种访问速度比内存快的多的告诉缓存寄存器,用来存当前访问的若干页表项的,以此对应,内存中的页表常称为慢表).以及两级页表.
  
      * 基本分段存储
  
        跟分页的方式的区别就是分的是段而不是页.
  
        进程的地址空间按照程序自身的逻辑关系划分为若干个段,每个段都有一个段名(在低级语言中,程序员使用段名来编程),每个段从0开始编址.操作系统进行内存分配的时候,也是按段为单位进行分配的,每个段在内存中占据连续的内存空间,但各个段之间可用不相邻.
  
        分段系统的逻辑地址由段号(段名)和段内地址(段内偏移量)构成.段号的位数决定每个进程最多可用分几个段,段内地址位数决定了每个段的最大长度是多少.
  
        为了保证程序的正常运行,操作系统会为每个进程维护一张段映射表,也就是段表.里面存储的就是该进程各个段的段名以及段长和段的基址.
  
      * 段页式存储
  
        在单分段和单分页存储的方式中,分页为的是增加空间的利用率,但是分页并不方便按照逻辑模块实现信息的共享和保护.而在分段的方式中,为的是更方便的实现按逻辑模块实现信息共享和保护,但空间利用率又不高,为了综合两种方法的优点,就出现了段页式存储的方式.
        
        段页式存储的方式是这样的 : 先将进程按逻辑模块分段,再将各段分页,再将内存空间分为大小相同的内存快(页框).在段页式存储方式中的逻辑地址由段号(段号的位数决定了进程最大能够分段的数量),页号(位数决定了一个段能分为多少个页),页内偏移量(位数决定页面大小,内存块的大小)组成.这点与分段中的逻辑地址有所差别.这种方式也存在段表和页表.段表由各个包含段号,页表长度,页表存放块号组成的段表项组成,页表存放的是由页号,页面存放的内存块号组成的页表项构成.
  
  * 能够提供某种计数从逻辑上对内存空间进行扩充(比如虚拟内存技术)
  
    * 覆盖技术
  
      将程序分为多个段(多个模块),常用的段常驻内存,不常用的段在需要时才调入.内存中分为一个固定区和一个覆盖区,需要常驻内存的段放在固定区,调入后不再调出,直到程序运行结束.不常用的段放在覆盖区,需要时调入内存,不用时调出.
  
      这种技术需要用户声明覆盖结构,以让操作系统根据这个结构进行覆盖操作.对用户编程要求比较高.
  
    * 交换技术
  
      内存空间紧张时,系统将内存中某些进程暂时换出外存,把外存中某些已经具备运行条件的进程换入内存.也就是我们的中级调度的过程.
  
    * 虚拟存储技术
  
      虚拟内存技术是对传统的内存扩充技术缺点(一次性,驻留性)的改进和增强.
  
      * 局部性原理
        * 时间局部性 : 如果执行了程序中的某条指令,那么不久后这条语句很有可能再次执行;如果某个数据被访问过,那么一段时间内这个数据也很有可能再次会被访问.
        * 空间局部性 : 一旦程序访问了某个存储单元,在不久后,其附近的存储单元也很可能被访问到.
        * 高速缓存技术 : 将近期可能会频繁访问到的数据放到速度更高的存储器中,暂时用不到的数据放在低速的存储器中.(存储器的速度(由低到高) : 外存 -> 内存 -> 高速缓存区 -> 寄存器). 
  
      虚拟内存技术就是利用局部性原理,把程序运行会需要的模块先装入内存,暂时用不到的放在外存,就可以让程序开始执行了.在程序执行的过程中,当访问的信息不在内存,操作系统此时就会去外存调入那些程序需要的数据或者模块,然后继续执行程序.如果内存空间不足,操作系统会将内存中展示用不到的信息换出到外存里去,这样在程序运行的时候,看起来内存的容量比实际的要大.这就是虚拟技术.虚拟内存的最大容量由计算机的地址结构,也就是CPU的寻址范围来决定的,虚拟内存的实际容量是内存和外存的容量综合和CPU寻址范围中的较小值决定的.
  
      * 虚拟内存的实现
  
        * 请求分页存储
        * 请求分段存储
        * 请求段页式存储
  
        虚拟内存的实现与传统的内存分配管理技术的主要区别就是 : 在程序执行的过程中,所访问的数据不在内存中,虚拟内存技术可由操作系统去外存里拿,而且能在内存不足时调出不用的数据.传统的内存管理技术是会常驻内存的.虚拟内存技术的内存管理,也就是在传统模式上新增了请求调页/段功能和页面置换功能,也就是实现了虚拟内存比传统内存管理多出来的那些功能特点.
  
  * 地址转换功能,负责程序的逻辑地址与物理地址的转换(由链接程序和装入程序提供)
  
  * 内存保护功能,保证各个进程在各自的内存空间内运行,互不干扰
  
    * 使用上下限寄存器实现内存保护 : 存放程序的上下限地址.访问不可越界
    * 使用重定位寄存器(又称基址寄存器)和界地址寄存器(又称限长寄存器).进行越界检查.重定位寄存器中存放的是进程的起始物理地址,界地址寄存器存放的是进程的最大逻辑地址.

## 文件管理

文件管理是操作系统的基本功能之一.

文件是一组有意义的信息/数据的集合.

#### 文件属性及其组织方式

* 文件名

  就是文件的名称,主要是方便用户寻找文件,同一目录下不允许有同名文件

* 标识符

  一个系统内的各文件标识符唯一,但是这个标识符对用户来说是没有可读性的,它是给操作系统区分文件用的

* 文件类型

  指明文件类型.

* 文件位置

  文件存放的路径(用户用的),文件在外存的地址(操作系统用的)

* 文件大小

  文件所占空间大小

* 创建时间,修改时间,文件所有者

* 保护信息

  对文件进行保护的访问控制信息.

文件的组织结构分为无结构文件和有结构文件

有结构文件是由一个个的基本数据项组成的,无结构文件就是有一系列字节流或者字符流构成.

文件之间是由目录,也就是文件夹的形式来组织的.

外存和内存类似,也是由一个个内存块组成的,也有地址,也需要物理地址和逻辑地址的转换.操作系统是用块的形式来为文件的,在一个块中,即使一个文件很小,它也是独占一个块的.
